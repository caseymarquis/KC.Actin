The idea is that the whole application should be a single project. You deploy everything everywhere, because deployment is cheap.

You mark classes with attributes which state the circumstances under which they should start.

I'm not 100% sure how this should ideally look yet. Should we just mark the top level singletons, and everything happens from there? Probably, as simple is usually good.

The thing about that is there are going to be differences in how things get deployed. linux vs windows. It's not always going to make sense to share everything.
But sometimes, it makes a TON of sense to have everything in a single project. When normally everything is on the same system and just accessed via 127.0.0.1 for example.
This is the case for actors which are just looking for process separation for example.

So, that said, there are really two different use cases which should potentially have different tools.

1. I want to deploy an 'application' which:
-runs in a single type of environment.
-updates all portions at the same time.
-is in a single project

2. 
I want different applications to
-easily communicate with each other. 
-operate independently

In an ideal world, there would be a way of type-checking and displaying compatibility.
In theory this could be on the user, and require them to do proper sem-ver.
We could look at the versions and figure out if an update is required for things
to continue to work.

The easier method is for everything to update at once, but that's not always realistic.

I want static type checking of communications.

An unaddressed topic is how dynamic the location of specific actors is.

On the one hand, we want the convenience of defining this in code.
On the other hand, we want the ability to dynamically configure
things on the fly. This has the danger of allowing users
to break things though.

One imagined scenario.

You have an application which uses serial ports which are dependent on an external driver.
Sometimes, you need to restart the computer to fix the driver.
Normally, you talk to these ports in the same process.
However, one deployed instance is critical, and should not be restarted during operation.
You start an instance of the application on another PC adjancent to the critical instance,
and you dynamically point the critical instance at this one. You tell it that it should now
run all processes of type X on this system instead.

That would be really neat.

So, how would you make that happen?

The main thing is API browsability and compatibility.
Also, the tools for this need to be built straight into the
library.

You should be able to browse and see:
-What types of actors does the instance know about?
-Which of these actors are capable of being remotely managed?
--I think this is largely based on the dependencies and public interfaces of these actors.
--That said, we should be able to define a subset of functionality which allows an
--actor to be remotely managed.

Managed actors would need a handle.

Parents would need a persistent record of where there children are.
If the parent restarts, it needs to be able to check if its children already
exist. It also probably needs options for what to do when this happens.
This is probably as simple as children being notified about a parent restart.
That said, perhaps all actors should be notified about the status of all of their
dependencies, and then make decisions about what to do when they are unavailable.
Helper functionality could be built into the actor class. That said,
that's not really ideal. The basic situation is that an actor either
should run, or should not run, when a particular dependency or set of
dependencies is down. While this could be manually wired together
in the run code of each actor, it would be better if this was built into
the definition of dependencies. This should be explicit, so that
applications have made decisions about this (and developers learn about it)
from the beginning. This would mean there should be Critical and Non-Critical
attributes.

I like the idea of calling these attributes:
[Needs]
and
[Wants]

If something an actor needs is not available, then the actor should not run.
Tooling should make it clear which actors are in this state.
When the actor runs, it assumes the things it [Needs] are available.
The actor needs to check the status of the things that it [Wants].

Should an actor be disposed of if it lacks the things it needs?
Or should it just pause itself?

On the one hand, this seems like an application specific question.
On the other hand, killing actors early and often prevents them
from getting stuck forever.

A third option is to set an amount of time that an actor is willing to
remain in stasis. ie, if I don't have everything I need for more than
one minute, then I should be disposed. Almost biological in nature.

That gives us three categories:
[Need(canWait: Time = Something Small)]: Actor will not run if this dependency is not available. Actor will be killed if this dependency is unavailable for x amount of time. If not specified, this time should be something like 15 seconds.
[Demand]: Actor will not run unless this dependency is available.
[Request]: Actor will run if this dependency is not available, and must manually check if it exists.

But we also have dependency relationships:
[Singleton]: Where a singleton lives needs to be decided at the top level of an application.
Perhaps when a class is defined and labeled with [Singleton]
[Parent]
[Sibling]
[Instance] //Effectively child. Should it be called child?
[Specified]

This only really matters once you're in a distributed application,
as when everything is in the same process, 

Aside: Distributed applications should be avoided except where they're REALLY needed.
Let's say you've set up a distributed application on two servers. You now can't
just move the application over... Or... maybe you can?
If one of the systems is always the primary system, and this is the
system which contains the configuration, then if the tooling is good
enough, you could simply move the main application, and its configuration
would come with it. You could then swap out the subprocesses independently.


Secure Communications:
It would be really nice to separate the method of secure
communications into its own transparent layer.

The thing is, secure communications today are not secure in 10 years.
The handling of secure communciations should be built into the tooling.
We should be able to verify if a remote actor is trusted or not,
and we should be able to establish this trust in different ways.

Realistically, most applications can function with something as simple as:
-When I was first run, someone opened my parent, pointed it to me (or it automatically saw me)
and said I should trust its cert. Someone did the same thing on the child.
The parent was then able to spawn actors on the child.

Fast Communications:
Ecrypting communications has a performance penalty.
That said, the security benefits of latest supported encryption by default
outweigh them performance penalties in my mind.

Detection Protocol:
There should definitely be an on by default 'I Exist'
packet which is periodically sent from each system running actors.
This would allow tooling to automically pick up what's running,
and would simplify establishing trust between actors
This brings up the concept of how to you label what exists.

Labeling Remote Actors:
Application Type: The name of the application in question which can remotely be called.
Application Id: The i


App Instance 1
    -App Instance 2 (address)


Aside: I want to be able to monitor remote actor instances and get information from them.